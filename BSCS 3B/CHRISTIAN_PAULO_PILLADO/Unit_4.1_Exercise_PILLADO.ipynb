{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269f6625",
   "metadata": {},
   "source": [
    "1.\tPerforming it manually. In manually developing a Naïve Bayes model, create methods that will do the following:\n",
    "\n",
    "a.\tGenerate a Bag of Words (for word frequency)\n",
    "\n",
    "b.\tCalculate the prior for the class HAM and SPAM\n",
    "\n",
    "c.\tCalculate the likelihood of the tokens in the vocabulary with respect to the class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ef8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50794fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded:\n",
      "1. [SPAM] Free money now!!!\n",
      "2. [HAM] Hi mom, how are you?\n",
      "3. [SPAM] Lowest price for your meds\n",
      "4. [HAM] Are we still on for dinner?\n",
      "5. [SPAM] Win a free iPhone today\n",
      "6. [HAM] Let's catch up tomorrow at the office\n",
      "7. [HAM] Meeting at 3 PM tomorrow\n",
      "8. [SPAM] Get 50% off, limited time!\n",
      "9. [HAM] Team meeting in the office\n",
      "10. [SPAM] Click here for prizes!\n",
      "11. [HAM] Can you send the report?\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "documents = [\n",
    "    (\"Free money now!!!\", \"SPAM\"),\n",
    "    (\"Hi mom, how are you?\", \"HAM\"),\n",
    "    (\"Lowest price for your meds\", \"SPAM\"),\n",
    "    (\"Are we still on for dinner?\", \"HAM\"),\n",
    "    (\"Win a free iPhone today\", \"SPAM\"),\n",
    "    (\"Let's catch up tomorrow at the office\", \"HAM\"),\n",
    "    (\"Meeting at 3 PM tomorrow\", \"HAM\"),\n",
    "    (\"Get 50% off, limited time!\", \"SPAM\"),\n",
    "    (\"Team meeting in the office\", \"HAM\"),\n",
    "    (\"Click here for prizes!\", \"SPAM\"),\n",
    "    (\"Can you send the report?\", \"HAM\")\n",
    "]\n",
    "\n",
    "print(\"Dataset loaded:\")\n",
    "for i, (doc, label) in enumerate(documents, 1):\n",
    "    print(f\"{i}. [{label}] {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08c7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba92a55",
   "metadata": {},
   "source": [
    "a. Generate Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1519ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag of Words (word frequencies):\n",
      "SPAM: {'free': 2, 'money': 1, 'now': 1, 'lowest': 1, 'price': 1, 'for': 2, 'your': 1, 'meds': 1, 'win': 1, 'a': 1, 'iphone': 1, 'today': 1, 'get': 1, '50': 1, 'off': 1, 'limited': 1, 'time': 1, 'click': 1, 'here': 1, 'prizes': 1}\n",
      "HAM: {'hi': 1, 'mom': 1, 'how': 1, 'are': 2, 'you': 2, 'we': 1, 'still': 1, 'on': 1, 'for': 1, 'dinner': 1, 'let': 1, 's': 1, 'catch': 1, 'up': 1, 'tomorrow': 2, 'at': 2, 'the': 3, 'office': 2, 'meeting': 2, '3': 1, 'pm': 1, 'team': 1, 'in': 1, 'can': 1, 'send': 1, 'report': 1}\n",
      "\n",
      "Vocabulary:\n",
      "['3', '50', 'a', 'are', 'at', 'can', 'catch', 'click', 'dinner', 'for', 'free', 'get', 'here', 'hi', 'how', 'in', 'iphone', 'let', 'limited', 'lowest', 'meds', 'meeting', 'mom', 'money', 'now', 'off', 'office', 'on', 'pm', 'price', 'prizes', 'report', 's', 'send', 'still', 'team', 'the', 'time', 'today', 'tomorrow', 'up', 'we', 'win', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bow = {'SPAM': Counter(), 'HAM': Counter()}\n",
    "class_counts = {'SPAM': 0, 'HAM': 0}\n",
    "vocab = set()\n",
    "\n",
    "for doc, label in documents:\n",
    "    tokens = tokenize(doc)\n",
    "    bow[label].update(tokens)\n",
    "    class_counts[label] += 1\n",
    "    vocab.update(tokens)\n",
    "\n",
    "print(\"\\nBag of Words (word frequencies):\")\n",
    "for label in bow:\n",
    "    print(f\"{label}: {dict(bow[label])}\")\n",
    "\n",
    "print(\"\\nVocabulary:\")\n",
    "print(sorted(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754d126",
   "metadata": {},
   "source": [
    "b.\tCalculate the prior for the class HAM and SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ace1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Priors:\n",
      "P(SPAM) = 0.455\n",
      "P(HAM) = 0.545\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate priors\n",
    "total_docs = sum(class_counts.values())\n",
    "priors = {label: class_counts[label] / total_docs for label in class_counts}\n",
    "print(\"\\nPriors:\")\n",
    "for label in priors:\n",
    "    print(f\"P({label}) = {priors[label]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3f2c7",
   "metadata": {},
   "source": [
    "c. Calculate the likelihood of the tokens in the vocabulary with respect to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8bd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Likelihoods (P(word|class)):\n",
      "\n",
      "Class: SPAM\n",
      "P(3|SPAM) = 0.0149\n",
      "P(50|SPAM) = 0.0299\n",
      "P(a|SPAM) = 0.0299\n",
      "P(are|SPAM) = 0.0149\n",
      "P(at|SPAM) = 0.0149\n",
      "P(can|SPAM) = 0.0149\n",
      "P(catch|SPAM) = 0.0149\n",
      "P(click|SPAM) = 0.0299\n",
      "P(dinner|SPAM) = 0.0149\n",
      "P(for|SPAM) = 0.0448\n",
      "P(free|SPAM) = 0.0448\n",
      "P(get|SPAM) = 0.0299\n",
      "P(here|SPAM) = 0.0299\n",
      "P(hi|SPAM) = 0.0149\n",
      "P(how|SPAM) = 0.0149\n",
      "P(in|SPAM) = 0.0149\n",
      "P(iphone|SPAM) = 0.0299\n",
      "P(let|SPAM) = 0.0149\n",
      "P(limited|SPAM) = 0.0299\n",
      "P(lowest|SPAM) = 0.0299\n",
      "P(meds|SPAM) = 0.0299\n",
      "P(meeting|SPAM) = 0.0149\n",
      "P(mom|SPAM) = 0.0149\n",
      "P(money|SPAM) = 0.0299\n",
      "P(now|SPAM) = 0.0299\n",
      "P(off|SPAM) = 0.0299\n",
      "P(office|SPAM) = 0.0149\n",
      "P(on|SPAM) = 0.0149\n",
      "P(pm|SPAM) = 0.0149\n",
      "P(price|SPAM) = 0.0299\n",
      "P(prizes|SPAM) = 0.0299\n",
      "P(report|SPAM) = 0.0149\n",
      "P(s|SPAM) = 0.0149\n",
      "P(send|SPAM) = 0.0149\n",
      "P(still|SPAM) = 0.0149\n",
      "P(team|SPAM) = 0.0149\n",
      "P(the|SPAM) = 0.0149\n",
      "P(time|SPAM) = 0.0299\n",
      "P(today|SPAM) = 0.0299\n",
      "P(tomorrow|SPAM) = 0.0149\n",
      "P(up|SPAM) = 0.0149\n",
      "P(we|SPAM) = 0.0149\n",
      "P(win|SPAM) = 0.0299\n",
      "P(you|SPAM) = 0.0149\n",
      "P(your|SPAM) = 0.0299\n",
      "\n",
      "Class: HAM\n",
      "P(3|HAM) = 0.0253\n",
      "P(50|HAM) = 0.0127\n",
      "P(a|HAM) = 0.0127\n",
      "P(are|HAM) = 0.0380\n",
      "P(at|HAM) = 0.0380\n",
      "P(can|HAM) = 0.0253\n",
      "P(catch|HAM) = 0.0253\n",
      "P(click|HAM) = 0.0127\n",
      "P(dinner|HAM) = 0.0253\n",
      "P(for|HAM) = 0.0253\n",
      "P(free|HAM) = 0.0127\n",
      "P(get|HAM) = 0.0127\n",
      "P(here|HAM) = 0.0127\n",
      "P(hi|HAM) = 0.0253\n",
      "P(how|HAM) = 0.0253\n",
      "P(in|HAM) = 0.0253\n",
      "P(iphone|HAM) = 0.0127\n",
      "P(let|HAM) = 0.0253\n",
      "P(limited|HAM) = 0.0127\n",
      "P(lowest|HAM) = 0.0127\n",
      "P(meds|HAM) = 0.0127\n",
      "P(meeting|HAM) = 0.0380\n",
      "P(mom|HAM) = 0.0253\n",
      "P(money|HAM) = 0.0127\n",
      "P(now|HAM) = 0.0127\n",
      "P(off|HAM) = 0.0127\n",
      "P(office|HAM) = 0.0380\n",
      "P(on|HAM) = 0.0253\n",
      "P(pm|HAM) = 0.0253\n",
      "P(price|HAM) = 0.0127\n",
      "P(prizes|HAM) = 0.0127\n",
      "P(report|HAM) = 0.0253\n",
      "P(s|HAM) = 0.0253\n",
      "P(send|HAM) = 0.0253\n",
      "P(still|HAM) = 0.0253\n",
      "P(team|HAM) = 0.0253\n",
      "P(the|HAM) = 0.0506\n",
      "P(time|HAM) = 0.0127\n",
      "P(today|HAM) = 0.0127\n",
      "P(tomorrow|HAM) = 0.0380\n",
      "P(up|HAM) = 0.0253\n",
      "P(we|HAM) = 0.0253\n",
      "P(win|HAM) = 0.0127\n",
      "P(you|HAM) = 0.0380\n",
      "P(your|HAM) = 0.0127\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate likelihoods with Laplace smoothing\n",
    "likelihoods = {label: {} for label in bow}\n",
    "for label in bow:\n",
    "    total_words = sum(bow[label].values())\n",
    "    for word in vocab:\n",
    "        # Laplace smoothing\n",
    "        likelihoods[label][word] = (bow[label][word] + 1) / (total_words + len(vocab))\n",
    "\n",
    "print(\"\\nLikelihoods (P(word|class)):\")\n",
    "for label in likelihoods:\n",
    "    print(f\"\\nClass: {label}\")\n",
    "    for word in sorted(vocab):\n",
    "        print(f\"P({word}|{label}) = {likelihoods[label][word]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a4ccf",
   "metadata": {},
   "source": [
    "d. Determine the class of the following test sentence:\n",
    "\n",
    "i.\tLimited offer, click here!\n",
    "\n",
    "ii.\tMeeting at 2 PM with the manager.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6b3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Limited offer, click here!\"\n",
      "Predicted class: SPAM\n",
      "\n",
      "Sentence: \"Meeting at 2 PM with the manager.\"\n",
      "Predicted class: HAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_sentences = [\n",
    "    \"Limited offer, click here!\",\n",
    "    \"Meeting at 2 PM with the manager.\"\n",
    "]\n",
    "\n",
    "for test in test_sentences:\n",
    "    tokens = tokenize(test)\n",
    "    scores = {}\n",
    "    for label in ['SPAM', 'HAM']:\n",
    "        # Start with the log prior\n",
    "        log_prob = math.log(priors[label])\n",
    "        total_words = sum(bow[label].values())\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                log_prob += math.log(likelihoods[label][token])\n",
    "            else:\n",
    "                # Handle unknown words with Laplace smoothing\n",
    "                log_prob += math.log(1 / (total_words + len(vocab)))\n",
    "        scores[label] = log_prob\n",
    "    predicted = max(scores, key=scores.get)\n",
    "    print(f\"Sentence: \\\"{test}\\\"\")\n",
    "    print(f\"Predicted class: {predicted}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f83d5",
   "metadata": {},
   "source": [
    "2.\tUsing Scikit-Learn. Use the scikit-learn package to train and test a Multinomial Naïve Bayes classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14b6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Limited offer, click here!\"\n",
      "Predicted class: SPAM\n",
      "\n",
      "Sentence: \"Meeting at 2 PM with the manager.\"\n",
      "Predicted class: HAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Prepare data\n",
    "texts = [doc for doc, label in documents]\n",
    "labels = [label for doc, label in documents]\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, labels)\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"Limited offer, click here!\",\n",
    "    \"Meeting at 2 PM with the manager.\"\n",
    "]\n",
    "\n",
    "# Transform and predict\n",
    "X_test = vectorizer.transform(test_sentences)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"Sentence: \\\"{sent}\\\"\")\n",
    "    print(f\"Predicted class: {pred}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
